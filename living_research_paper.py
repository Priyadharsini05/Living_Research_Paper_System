# -*- coding: utf-8 -*-
"""Living_research_paper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_3eB4xkTsA-Kv64S6DBL7lKHJcSfOUzF
"""

!pip install langchain==0.1.16
!pip install faiss-cpu
!pip install sentence-transformers
!pip install pypdf
!pip install transformers accelerate torch

from google.colab import files

uploaded = files.upload()

import os
from langchain.document_loaders import PyPDFLoader

documents = []

for file in os.listdir():
    if file.endswith(".pdf"):
        loader = PyPDFLoader(file)
        pages = loader.load()
        documents.extend(pages)
        print(f"Loaded {file} with {len(pages)} pages")

print("Total pages loaded:", len(documents))

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=200
)

chunks = text_splitter.split_documents(documents)

print("Total chunks created:", len(chunks))

from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vectorstore = FAISS.from_documents(chunks, embeddings)

print("FAISS vector store created successfully")

from transformers import pipeline

llm = pipeline(
    "text2text-generation",
    model="google/flan-t5-base",
    max_length=512
)

print("LLM loaded successfully")

def rag_answer(question, vectorstore, k=4):
    # 1. Retrieve relevant chunks
    docs = vectorstore.similarity_search(question, k=k)

    # 2. Combine retrieved text
    context = "\n\n".join([doc.page_content for doc in docs])

    # 3. Prompt
    prompt = f"""
    You are an academic research assistant.

    Use ONLY the context below to answer the question.
    If the answer is not present, say so clearly.

    Context:
    {context}

    Question:
    {question}

    Answer:
    """

    # 4. Generate answer
    response = llm(prompt)

    return response[0]["generated_text"]

question = "What neural network architectures are commonly used in these papers, and why are they suitable for text data?"

answer = rag_answer(question, vectorstore)

print("QUESTION:")
print(question)

print("\nANSWER:")
print(answer)